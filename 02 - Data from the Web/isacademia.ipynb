{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing data from IS-Academia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first set up our environment by importing required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup as BSoup\n",
    "from IPython.display import Image\n",
    "import urllib.request, time, random\n",
    "#import html5lib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding IS-Academia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make automatic requests to IS-Academia, we need to understand how to pass it requests and  find the values of the request parameters we're interested in.\n",
    "\n",
    "We use Postman to sniff the requests and find the parameters we'll need to play with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We highlight these paramets in the Postman screenshot below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Image(filename='assets/postman.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameters are:\n",
    "* **ww_x_GPS**: is used to select a student list when the request returns several, -1 allows us to display all the lists in the same table\n",
    "* **ww_i_reportModel**: is constant, same for **ww_i_reportModelXsl**\n",
    "* **ww_x_UNITE_ACAD**: is used to select a section (eg. 'Informatique')\n",
    "* **ww_x_PERIODE_ACAD**: is used to select the academic period (eg. '2016-2017')\n",
    "* we set **ww_x_PERIODE_PEDAGO** and **ww_x_HIVERETE** to 'null' to get all students enrolled in the section, regardless of their semester"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The IS-Academia form is hard to reach with Beautiful Soup (seems dynamically generated), so we copied its html and saved it to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "form = 'assets/isform.html'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(form, 'r') as html:\n",
    "    r = html.read()\n",
    "soup = BSoup(r, 'lxml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find the values we use beautiful soup to parse the form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values are encoded in the html 'option' tag that lists the choices the user can select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "options = soup.find_all('option')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We extract the name of the option and its parameter value and combine it in a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "values = []\n",
    "names = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for opt in options:\n",
    "    v = opt['value']\n",
    "    n = opt.get_text()\n",
    "    if opt['value'] != 'null' or 1:\n",
    "        values.append(v)\n",
    "        names.append(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'values': values, 'names': names})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per section and per period we will extract all students at once, so we only need section and period values. We thus split our DataFrame accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subjects = df[1:20]\n",
    "years = df[21:31]\n",
    "subjects.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "years.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, in this exercise we only consider 'Informatique', so we keep only that row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subjects = subjects.loc[subjects.names == 'Informatique']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requesting, cleaning and combining data from IS-Academia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This whole process is abstracted in our ISA() class. We refer you to the inline comments of its \\_\\_init\\_\\_ function to understand the various steps of the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ISA():\n",
    "    \"\"\" this class is used to build a usable DataFrame from a request to IS-Academia \n",
    "    \n",
    "    Args:\n",
    "        name (str): name of EPFL section\n",
    "        period (str): academic period (years)\n",
    "        subj (str): the value code for EPFL section\n",
    "        year (str): the value code for academic period\n",
    "        season (str): the value code for winter/spring semester\n",
    "        semester (str): the value code for semester\n",
    "    \n",
    "    Attributes:\n",
    "        fileName (str): file name for saving\n",
    "        url (str): the parametrized url for \n",
    "        soup (str): souped up requested HTML\n",
    "        hasContent (bool): bool to check that request isn't empty\n",
    "        tables (array of strings): list of HTML subtables, None if !hasContent\n",
    "        frames (array of DataFrames): list of DataFrames of subtables, None if !hasContent\n",
    "        hasFrames (bool): bool to check that object does have a frame (see inline comment)\n",
    "        bigFrame (DataFrame): final concatenated and reindexed DataFrame, None if !hasFrames\n",
    "    \"\"\"\n",
    "    # ISA base url and save folder\n",
    "    baseUrl = 'http://isa.epfl.ch/imoniteur_ISAP/!GEDPUBLICREPORTS.html?ww_x_GPS=-1&ww_i_reportModel=133685247&ww_i_reportModelXsl=133685270'\n",
    "    folder = 'data/'\n",
    "    \n",
    "    ################################\n",
    "    #### Initializing functions ####\n",
    "    ################################\n",
    "    \n",
    "    def getFileName(self, name, period):\n",
    "        \"\"\" used to prepare the file name for saving\n",
    "        \n",
    "        Args:\n",
    "            name (str): the name of EPFL section\n",
    "            period (str): the academic period (years)\n",
    "            \n",
    "        Returns:\n",
    "            str: underscored concatenated name\n",
    "        \n",
    "        \"\"\"\n",
    "        name = name.lower()\n",
    "        name = name.replace(' ', '_')\n",
    "        period = period.replace('-', '_')\n",
    "        return name+'_'+period\n",
    "    \n",
    "    def getUrl(self, subj, year, season, semester):\n",
    "        \"\"\" Builds the request url\n",
    "        \n",
    "        Args:\n",
    "            subj (str): the value code for EPFL section\n",
    "            year (str): the value code for academic period\n",
    "            season (str): the value code for winter/spring semester\n",
    "            semester (str): the value code for semester\n",
    "            \n",
    "        Returns:\n",
    "            str: url with appropriate parameters\n",
    "        \"\"\"\n",
    "        paramSubj = '&ww_x_UNITE_ACAD='+subj\n",
    "        paramYear = '&ww_x_PERIODE_ACAD='+year\n",
    "        paramSemester = '&ww_x_PERIODE_PEDAGO='+semester\n",
    "        paramSeason = '&ww_x_HIVERETE='+season\n",
    "        url = self.baseUrl+paramSubj+paramYear+paramSemester+paramSeason\n",
    "        return url\n",
    "    \n",
    "    def getSoup(self, url):\n",
    "        \"\"\" makes request and gets souped HTML \n",
    "        \n",
    "        Args:\n",
    "            url (str): proper url for request\n",
    "            \n",
    "        Returns:\n",
    "            BSoup object: souped up HTML\n",
    "        \"\"\"\n",
    "        with urllib.request.urlopen(url) as html:\n",
    "            r = html.read()\n",
    "        return BSoup(r, 'lxml')\n",
    "    \n",
    "    ################################\n",
    "    \n",
    "    ###################################\n",
    "    #### HTML parsing and cleaning ####\n",
    "    ###################################\n",
    "    \n",
    "    def tableToList(self, soup):\n",
    "        \"\"\" transforms html table into list of rows (BSoup objects) \n",
    "        \n",
    "        Args:\n",
    "            soup (BSoup object): souped up HTML\n",
    "            \n",
    "        Returns:\n",
    "            array of BSoup objects: list of table rows\n",
    "        \"\"\"\n",
    "        return soup.find('table').find_all('tr')\n",
    "    \n",
    "    def cleanHTMLTable(self, tr):\n",
    "        \"\"\" takes row list and returns pandas usable table, gets rid of the initial title row\n",
    "        \n",
    "        Args:\n",
    "            tr (array of BSoup objects): list of table rows\n",
    "            \n",
    "        Returns:\n",
    "            str: HTML table in a string\n",
    "        \"\"\"\n",
    "        # Replacing the title row with a <table> tag. The title info will\n",
    "        # be added as a column of the DataFrame\n",
    "        tr[0] = '<table>'\n",
    "        # Initialize str\n",
    "        table = ''\n",
    "        # Looping through rows and filling the table str\n",
    "        for t in tr:\n",
    "            table += str(t)\n",
    "        # Closing the table\n",
    "        table += '</table>'\n",
    "        return table\n",
    "    \n",
    "    ###################################\n",
    "\n",
    "    ##########################################\n",
    "    #### Data handling and transformation ####\n",
    "    ##########################################\n",
    "    \n",
    "    # we have a table for the whole section, but it is made of smaller semester-specific tables\n",
    "    # concatenated together. we separate them with this function\n",
    "    def sepTables(self, soup):\n",
    "        \"\"\" fills an array with subtables of our original table \n",
    "        \n",
    "        Args:\n",
    "            soup (BSoup object): souped up HTML\n",
    "            \n",
    "        Returns:\n",
    "            array of arrays of strings: list of ['subtable name', 'subtable (str)']\n",
    "        \"\"\"\n",
    "        \n",
    "        # initializing array\n",
    "        tables = []\n",
    "        \n",
    "        # transforming the table into list of rows for manipulation\n",
    "        table = self.tableToList(soup)\n",
    "        \n",
    "        # we want to extract subtables, so with an outer loop we find subtable header,\n",
    "        # initialize a subtable and use an inner loop to fill it\n",
    "        \n",
    "        # start the outer loop\n",
    "        for idx, row in enumerate(table):\n",
    "            # test for subtable headers (they're the only ones with 'colspan')\n",
    "            if str(row).find('colspan') != -1:\n",
    "                \n",
    "                # we use the header text to name our subtable\n",
    "                text = row.get_text()\n",
    "                # we clean it\n",
    "                name = text[:text.find(u'\\n')]\n",
    "                \n",
    "                # initialize subtable array\n",
    "                subtable = [row]\n",
    "                # i is used to loop through subtable rows, starting below header\n",
    "                i = idx+1\n",
    "                # we check that we're not already at the end of table (eg empty subtable)\n",
    "                if i < len(table):\n",
    "                    # inner loop, checking we haven't reached a new subtable header\n",
    "                    while str(table[i]).find('colspan') == -1:\n",
    "                        subtable.append(table[i])\n",
    "                        i += 1\n",
    "                        # break if we reach end of table\n",
    "                        if i == len(table):\n",
    "                            break\n",
    "                # if subtable was empty, nullify it\n",
    "                if len(subtable) == 1:\n",
    "                    subtable = 'null'\n",
    "                # we add the subtable to our tables array\n",
    "                tables.append([name, subtable])\n",
    "\n",
    "        return tables\n",
    "    \n",
    "    # we transform each table into a frame\n",
    "    def tableToFrame(self, name, table):\n",
    "        \"\"\" takes a ISA html table and returns a DataFrame \n",
    "        \n",
    "        Args:\n",
    "            name (str): the name of the table section\n",
    "            table (str): HTML table\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame: cleaned DataFrame object for that table with name as added column \n",
    "        \"\"\"\n",
    "        # getting a clean HTML table with no title header\n",
    "        t = self.cleanHTMLTable(table)\n",
    "        # putting it in a dataframe\n",
    "        df = pd.read_html(t, header=0)\n",
    "        \n",
    "        # the dataframe we're looking for is somehow encapsulated so we retrieve it\n",
    "        df = df[0]\n",
    "        # getting rid of an unwanted column\n",
    "        df = df.drop('Unnamed: 11', axis=1)\n",
    "        \n",
    "        # adding a column with student type, this is where we store this information\n",
    "        df['type'] = name\n",
    "\n",
    "        return df\n",
    "    \n",
    "    # we loop through the HTML tables we have to transform them into frames\n",
    "    def tablesToFrames(self, tables):\n",
    "        \"\"\" fills an array with DataFrames corresponding to the HTML subtables the tables array\n",
    "        \n",
    "        Args:\n",
    "            tables (array of arrays): list of ['subtable name', 'subtable (str)']\n",
    "            \n",
    "        Returns:\n",
    "            array of DataFrames: list of DataFrames corresponding to the tables\n",
    "        \"\"\"\n",
    "        frames = []\n",
    "        \n",
    "        for t in tables:\n",
    "            name = t[0]\n",
    "            table = t[1]     \n",
    "            # skips subtables with no content\n",
    "            if table != 'null':\n",
    "                frame = self.tableToFrame(name, table)\n",
    "                frames.append(frame)\n",
    "                \n",
    "        return frames\n",
    "    \n",
    "    # finally we concatenate everything into a big frame\n",
    "    def concatFrames(self, frames):\n",
    "        \"\"\" returns a frame made of all subframes concatenated and reindexed \n",
    "        \n",
    "        Args:\n",
    "            frames (array of DataFrames): list of DataFrames\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame: final DataFrame with concatenated and reindexed subframes\n",
    "        \"\"\"\n",
    "        # make final df\n",
    "        final = frames[0]\n",
    "        for frame in frames[1:]:\n",
    "            final = pd.concat([final, frame], axis=0)\n",
    "\n",
    "        # we reset index to have an index over the whole complete frame\n",
    "        final = final.reset_index().drop('index', axis=1)\n",
    "        \n",
    "        return final\n",
    "    \n",
    "    ##########################################\n",
    "        \n",
    "    ########################\n",
    "    #### Initialization ####\n",
    "    ########################\n",
    "    def __init__(self, name, period, subj, year, season, semester):\n",
    "        \"\"\" Initializes and builds HTML subtables, sub-DataFrames and final DataFrames\n",
    "        \n",
    "        Args:\n",
    "            name (str): name of EPFL section\n",
    "            period (str): academic period (years)\n",
    "            subj (str): the value code for EPFL section\n",
    "            year (str): the value code for academic period\n",
    "            season (str): the value code for winter/spring semester\n",
    "            semester (str): the value code for semester\n",
    "        \"\"\"\n",
    "        # REQUESTING #\n",
    "        # Getting a clean file name for saving\n",
    "        self.fileName = self.getFileName(name, period)\n",
    "        # Getting the request url\n",
    "        self.url = self.getUrl(subj, year, season, semester)\n",
    "        # Getting the request HTML as a BSoup object\n",
    "        self.soup = self.getSoup(self.url)\n",
    "        \n",
    "        # WRANGLING #\n",
    "        # we use the functions above to prepare the data\n",
    "        \n",
    "        # check that the request didn't come back empty\n",
    "        self.hasContent = len(self.tableToList(self.soup)) > 1\n",
    "        if self.hasContent:\n",
    "            # Separating the BSoup HTML into HTML subtables\n",
    "            self.tables = self.sepTables(self.soup)\n",
    "            # Transforming the HTML subtables into DataFrames\n",
    "            self.frames = self.tablesToFrames(self.tables)\n",
    "        else:\n",
    "            self.tables = None\n",
    "            self.frames = None\n",
    "            \n",
    "        # check that there actually is a frame\n",
    "        # there is no frame when: request didn't come back empty but contained only\n",
    "        # empty subtables (more than one) (eg master humanites digitales I think)\n",
    "        self.hasFrames = self.frames != None and (len(self.frames) > 0)        \n",
    "        if self.hasFrames:\n",
    "            # concatenate everything into a final reindexed DataFrame\n",
    "            self.bigFrame = self.concatFrames(self.frames)\n",
    "        else:\n",
    "            self.bigFrame = None\n",
    "            \n",
    "    ########################\n",
    "    \n",
    "    ################       \n",
    "    #### Saving ####\n",
    "    ################\n",
    "    def save(self):\n",
    "        \"\"\" saves the final DataFrame to a file with fileName\n",
    "        \n",
    "            prints along to keep track\n",
    "        \"\"\"\n",
    "        # check that there is something to save\n",
    "        if self.hasFrames:\n",
    "            self.bigFrame.to_csv(self.folder+self.fileName+'.csv', sep=',', encoding='utf-8')\n",
    "            # print something to keep track\n",
    "            print('saved '+self.fileName+' to '+self.folder)\n",
    "        else:\n",
    "            # announce nothing has been saved\n",
    "            print(self.fileName+' has no content')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a loop to retrieve and save the IS-Academia records. In this exercise, 'subjects' is only 'Informatique', but the loop can be used to retrieve records throughouts subjects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set season and semester to null, since we're not this specific in our requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "season = 'null'\n",
    "semester = 'null'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def isaLoop(subjects, years):\n",
    "    \"\"\" loops through subject (outer) and years (inner) to collect and save ISA data\n",
    "    \n",
    "    Args:\n",
    "        subjects (DataFrame): frame containing all EPFL sections with names and param values\n",
    "        years (DataFrame): frame containing academic periods with names and param values\n",
    "        \n",
    "    Returns:\n",
    "        saves final DataFrame to file\n",
    "    \"\"\"\n",
    "    # start looping through subjects\n",
    "    for row in subjects.iterrows():\n",
    "        o = row[1]\n",
    "        name = o['names']\n",
    "        subj = o['values']\n",
    "        \n",
    "        # loop through years\n",
    "        for r in years.iterrows():\n",
    "            q = r[1]\n",
    "            period = q['names']\n",
    "            year = q['values']\n",
    "            \n",
    "            data = ISA(name, period, subj, year, season, semester)\n",
    "            data.save()\n",
    "            \n",
    "        # we set a small randomized waiting time to look less bot-like\n",
    "        time.sleep(round(random.uniform(1.5, 5),2))\n",
    "            \n",
    "    print('all done my man')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "isaLoop(subjects, years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
